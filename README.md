# Voice-Controlled Surgical Tool Detection using YOLO11n

This project demonstrates real-time **surgical tool detection** using the **YOLO11n** model with **voice commands** under varying environmental conditions (like blur, lighting, angles, blood). It supports live detection from a video file and listens continuously for spoken commands such as "forceps", "mayo", "scalpel", etc., to trigger detection of the specified tool.

## ğŸ”§ Features

- ğŸ¤ Voice-controlled object detection (no button presses required)
- ğŸ›  Detection of surgical tools using YOLO11n
- ğŸ’¡ Robust under challenging conditions: blur, lighting variations, blood presence, and diverse angles
- ğŸ§  Multi-threaded continuous listening + real-time detection
- ğŸ“¼ Real-time detection on looped video stream
- âœ… GPU-accelerated if available

## ğŸ–¼ï¸ Example Tools

- Forceps
- Hemostat
- Mayo
- Scalpel
- Syringe
- Stitch Scissors
- Episiotomy Scissors
- Cotton
- Gloves

## ğŸ—‚ï¸ Project Structure

```bash
ğŸ“ project-root/
â”‚
â”œâ”€â”€ model/                            # Contains trained YOLOv8/YOLO11n model
â”‚   â””â”€â”€ best.pt
â”œâ”€â”€ video/                            # Input surgical video(s)
â”‚   â””â”€â”€ v5.mp4
â”œâ”€â”€ main.py                           # Main script
â””â”€â”€ README.md
```

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/your-username/voice-guided-surgical-detection.git
cd voice-guided-surgical-detection
```

### 2. Install Dependencies

```bash
pip install numpy opencv-python sounddevice scipy SpeechRecognition torch ultralytics
```

### 3. Run the Script

```bash
python main.py
```

The system will begin listening for voice commands. Speak the name of a surgical tool (e.g., "forceps") and it will highlight that object in the video.

## ğŸ¯ Voice Commands

You can say any of the following:
```
"forceps", "hemostat", "mayo", "scalpel", "syringe", 
"stitch scissors", "episiotomy scissors", "cotton", "gloves", "exit"
```

Saying **"exit"** will stop the program.

## ğŸ’¡ Model Training

The YOLO11n model used here was trained on a **custom dataset of 6000+ surgical tool images** captured under edge conditions:
- Low light and overexposure
- Motion blur
- Blood-stained scenes
- Varied angles

The trained model achieved **92.7% accuracy** under these conditions.

## ğŸ–¥ï¸ Hardware

- Compatible with both CPU and GPU
- Real-time performance is better on CUDA-compatible GPU

## ğŸ“œ License

This project is open-source and available under the MIT License.

---

### ğŸ‘¨â€âš•ï¸ Made with â¤ï¸ for surgical AI research.
